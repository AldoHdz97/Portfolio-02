{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20c2b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your directory\n",
    "os.chdir(r\"C:\\Users\\aldoh\\OneDrive\\Escritorio\\Proyecto LLM Portx2\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cd0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!python preprocess_metrics.py\n",
    "#!python preprocess_sdm.py\n",
    "#!python preprocess_publications.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd14892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installed Dependencies\n",
    "#%pip install crewai\n",
    "#%pip install python-dotenv\n",
    "#%pip install anthropic\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "from crewai import Agent, Task, Crew, Process, LLM\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from typing import List, Dict, Any \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ============================================================================\n",
    "# LLM CONFIGURATIONS -------- Anthropic and OpenAI\n",
    "# ============================================================================\n",
    "llm = LLM(\n",
    "    model=\"claude-sonnet-4-5-20250929\",\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "llmc = LLM(\n",
    "    model=\"claude-3-5-haiku-20241022\",    # Cheaper\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "###################################################################\n",
    "llmgptc = LLM(\n",
    "    model=\"gpt-4o-mini-2024-07-18\",   # Cheaper\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    response_format={\"type\": \"json_object\"},             \n",
    ")\n",
    "llmgpt = LLM(\n",
    "    model=\"gpt-4o-2024-08-06\",        \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# IMPORT SCHEMAS\n",
    "# ============================================================================\n",
    "from schemas import (\n",
    "    ValidationReport,\n",
    "    InsightsReport, \n",
    "    FactCheckReport,\n",
    "    CampusInsight,\n",
    "    CampusValidation,\n",
    "    CampusFactCheck\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "#Process Publications Script\n",
    "#=============================================================================\n",
    "#!python preprocess_publications.py\n",
    "#                                   *Why run this script?*\n",
    "# This script preprocesses and analyzes social media publication data.\n",
    "# It filters top publications by creating a engagement score.\n",
    "# This is needed so we don't have memory issues with the LLM and CrewAI stored data. \n",
    "#=============================================================================\n",
    "\n",
    "# ============================================================================\n",
    "# AGENTS DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "agent_validator = Agent(\n",
    "    role=\"Data Completeness Validator\",\n",
    "\n",
    "    goal=\"Validate that ALL 20 campuses have complete data across three JSON files. \"\n",
    "         \"CRITICAL: You must check EXACTLY 20 campuses - no more, no less. \"\n",
    "         \"Use the EXACT campus_id from the JSON files - do NOT invent new IDs. \"\n",
    "         \"Generate a ValidationReport with CampusValidation for each of the 20 campuses.\",\n",
    "\n",
    "    backstory=\"You are a meticulous data validator who NEVER stops until all 20 campuses are validated. \"\n",
    "              \"You load all three JSON files and extract the EXACT campus_id values from them. \"\n",
    "              \"You create one CampusValidation entry per campus using their actual campus_id from the data. \"\n",
    "              \"You verify field presence and count exactly how many campuses exist. \"\n",
    "              \"CRITICAL RULES: \"\n",
    "              \"(1) Always validate all 20 campuses - never stop early \"\n",
    "              \"(2) Use exact campus_id from the JSON files - never modify them \"\n",
    "              \"(3) Double-check your output contains exactly 20 CampusValidation objects before returning \"\n",
    "              \"(4) If you find fewer than 20 campuses in a file, note this in the summary\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_insight = Agent(\n",
    "    role=\"University Campus Insight Writer\",\n",
    "\n",
    "    goal=\"Generate EXACTLY 20 comprehensive insights (one per campus) using only the ACTUAL data from three JSON files. \"\n",
    "         \"CRITICAL: You must generate all 20 insights in a single response - do not stop early. \"\n",
    "         \"Use ONLY the categor√≠a words (excepcional/sobresaliente/satisfactorio/regular/deficiente) - NEVER show numeric scores. \"\n",
    "         \"Calculate percentages from actual current_month vs previous_year_month data.\",\n",
    "\n",
    "    backstory=\"You are an expert analyst who ALWAYS completes the full task. \"\n",
    "              \"Your process: \"\n",
    "              \"(1) Load all three JSON files \"\n",
    "              \"(2) Create a list to store 20 insights \"\n",
    "              \"(3) For EACH campus_id in the data: \"\n",
    "              \"    a. Match data across all three files by campus_id \"\n",
    "              \"    b. Calculate REAL percentages: ((current - previous) / previous) * 100 \"\n",
    "              \"    c. Extract actual publication content from OUTBOUND_POST \"\n",
    "              \"    d. Use ONLY categor√≠a words from totales (visibilidad_categoria, resonancia_categoria, salud_de_marca_categoria) \"\n",
    "              \"    e. Write insight in Spanish using this EXACT format: \"\n",
    "              \"\\n\\n\"\n",
    "              \"Campus [NOMBRE COMPLETO]\\n\\n\"\n",
    "              \"En agosto 2025, el campus [nombre] present√≥ un desempe√±o [salud_de_marca_categoria]. \"\n",
    "              \"La visibilidad fue [visibilidad_categoria] y la resonancia [resonancia_categoria]. \"\n",
    "              \"El alcance [aument√≥/disminuy√≥] un [X.X]% y las interacciones [aumentaron/disminuyeron] un [X.X]% respecto al mismo mes del a√±o anterior. \"\n",
    "              \"\\n\\n\"\n",
    "              \"Entre las publicaciones destacadas se encuentran: [mencionar 2-3 temas/contenidos reales de OUTBOUND_POST]. \"\n",
    "              \"\\n\\n\"\n",
    "              \"Los comentarios [aumentaron/disminuyeron] un [X.X]% con respecto al a√±o anterior.\"\n",
    "              \"\\n\\n\"\n",
    "              \"(4) After generating all 20 insights, verify your output contains exactly 20 CampusInsight objects \"\n",
    "              \"(5) If you have fewer than 20, continue generating until you reach 20 \"\n",
    "              \"\\n\\n\"\n",
    "              \"CRITICAL RULES: \"\n",
    "              \"- NEVER show numeric scores (83, 175, etc.) - ONLY use categor√≠a words \"\n",
    "              \"- NEVER stop until you have 20 insights \"\n",
    "              \"- ALWAYS calculate percentages from actual numbers in the JSON \"\n",
    "              \"- NEVER use placeholder data or invented percentages\",\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "agent_quality = Agent(\n",
    "    role=\"Insight Accuracy Validator\",\n",
    "\n",
    "    goal=\"Verify EVERY claim in all 20 campus insights against source JSON files. \"\n",
    "         \"For EACH error found, create a FactCheckIssue object with all required fields. \"\n",
    "         \"CRITICAL: If you find errors, you MUST populate the issues_found array - never leave it empty.\",\n",
    "\n",
    "\n",
    "    backstory=\"You are a ruthless fact-checker who catches every inaccuracy. \"\n",
    "              \"Your process: \"\n",
    "              \"(1) Load all three JSON files \"\n",
    "              \"(2) For each of the 20 campus insights: \"\n",
    "              \"    a. Extract every numeric claim (percentages, scores, engagement numbers) \"\n",
    "              \"    b. Look up actual values in source JSONs by campus_id \"\n",
    "              \"    c. Verify percentage calculations: ((current - previous) / previous) * 100 \"\n",
    "              \"    d. For EACH error found, create FactCheckIssue with: \"\n",
    "              \"       - campus_id \"\n",
    "              \"       - campus_name \"\n",
    "              \"       - issue_type (percentage_error / score_error / publication_mismatch / invented_data) \"\n",
    "              \"       - incorrect_statement (exact quote from insight_text) \"\n",
    "              \"       - correct_information (what it should be with calculation) \"\n",
    "              \"       - severity (critical/high/medium/low) \"\n",
    "              \"    e. Check if numeric scores appear in text (should only show categor√≠as) \"\n",
    "              \"    f. Verify categor√≠a words match actual categoria from totales \"\n",
    "              \"(3) Count total issues across all campuses \"\n",
    "              \"(4) Calculate accuracy rate \"\n",
    "              \"\\n\\n\"\n",
    "              \"CRITICAL RULES: \"\n",
    "              \"- If insight shows '76.90 puntos' next to 'sobresaliente', flag as error (shouldn't show numbers) \"\n",
    "              \"- If percentage is off by >3%, flag with severity='high' \"\n",
    "              \"- If publication doesn't exist in top_8_posts, flag with severity='critical' \"\n",
    "              \"- If categor√≠a doesn't match actual data, flag with severity='medium' \"\n",
    "              \"- ALWAYS populate issues_found array when errors exist - never return empty array if you found problems\",\n",
    "\n",
    "\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# TASKS DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "task_validator = Task(\n",
    "    description=(\n",
    "        \"Validate data completeness for ALL 20 campuses. \"\n",
    "        \"\\n\\n\"\n",
    "        \"STEP-BY-STEP PROCESS: \"\n",
    "        \"1. Load Publicaciones_estructuradas_Top8.json and extract ALL campus_id values \"\n",
    "        \"2. Load metrics_estructurado.json and extract ALL campus_id values \"\n",
    "        \"3. Load sdm_estructurado.json and extract ALL campus_id values \"\n",
    "        \"4. Create a master list of unique campus_ids across all files \"\n",
    "        \"5. For EACH campus_id in the master list: \"\n",
    "        \"   - Check if it exists in publications with top_8_posts \"\n",
    "        \"   - Check if it exists in metrics with current_month and previous_year_month \"\n",
    "        \"   - Check if it exists in scores with facebook/twitter/instagram/totales \"\n",
    "        \"   - Create CampusValidation object using the EXACT campus_id from the files \"\n",
    "        \"6. Verify you have exactly 20 CampusValidation objects \"\n",
    "        \"7. If fewer than 20, identify which campuses are missing from which files \"\n",
    "        \"\\n\\n\"\n",
    "        \"CRITICAL: Do NOT modify campus_ids (CVA not CCV, GDL not CGD, TOL not CTO, QRO not CQR). \"\n",
    "        \"CRITICAL: Generate validations for ALL 20 campuses before returning.\"\n",
    "    ),\n",
    "\n",
    "    expected_output=\"ValidationReport with exactly 20 CampusValidation objects using correct campus_ids from source files\",\n",
    "    output_pydantic=ValidationReport,\n",
    "    agent=agent_validator,\n",
    ")\n",
    "\n",
    "task_insight = Task(\n",
    "    description=(\n",
    "        \"Generate insights for ALL 20 campuses in ONE response. \"\n",
    "        \"\\n\\n\"\n",
    "        \"STEP-BY-STEP PROCESS: \"\n",
    "        \"1. Load all three JSON files \"\n",
    "        \"2. Extract list of all campus_ids \"\n",
    "        \"3. Create empty insights list \"\n",
    "        \"4. FOR EACH campus_id (loop through all 20): \"\n",
    "        \"   a. Get publications data: top_8_posts for this campus_id \"\n",
    "        \"   b. Get metrics data: current_month and previous_year_month for this campus_id \"\n",
    "        \"   c. Get scores data: totales for this campus_id \"\n",
    "        \"   d. Calculate percentages: \"\n",
    "        \"      - alcance_pct = ((current.ALCANCE_TOTAL - prev.ALCANCE_TOTAL) / prev.ALCANCE_TOTAL) * 100 \"\n",
    "        \"      - interacciones_pct = ((current.INTERACCIONES_TOTALES - prev.INTERACCIONES_TOTALES) / prev.INTERACCIONES_TOTALES) * 100 \"\n",
    "        \"      - comentarios_pct = ((current.POST_COMMENTS__SUM - prev.POST_COMMENTS__SUM) / prev.POST_COMMENTS__SUM) * 100 \"\n",
    "        \"   e. Extract publication themes from OUTBOUND_POST (2-3 posts) \"\n",
    "        \"   f. Get categor√≠as: totales.visibilidad_categoria, totales.resonancia_categoria, totales.salud_de_marca_categoria \"\n",
    "        \"   g. Write insight using ONLY categor√≠a words (NO NUMBERS) \"\n",
    "        \"   h. Add CampusInsight to list \"\n",
    "        \"5. Verify insights list has 20 items \"\n",
    "        \"6. Return InsightsReport with all 20 insights \"\n",
    "        \"\\n\\n\"\n",
    "        \"FORMAT RULES: \"\n",
    "        \"- Use 'visibilidad fue excepcional' NOT 'visibilidad fue excepcional (175 puntos)' \"\n",
    "        \"- Show percentages as 'aument√≥ un 21.3%' NOT 'aument√≥ aproximadamente 21%' \"\n",
    "        \"- Mention publication themes NOT full OUTBOUND_POST text \"\n",
    "        \"\\n\\n\"\n",
    "        \"CRITICAL: Generate all 20 insights in a single response. Do not stop after 1 or 5 or 10. Count to 20.\"\n",
    "    ),\n",
    "    expected_output=\"InsightsReport with exactly 20 CampusInsight objects, each with calculated percentages and categor√≠a words only\",\n",
    "    output_pydantic=InsightsReport,\n",
    "    agent=agent_insight,\n",
    "    context=[task_validator],\n",
    ")\n",
    "\n",
    "task_quality = Task(\n",
    "    description=(\n",
    "        \"Fact-check ALL 20 campus insights against source data. \"\n",
    "        \"\\n\\n\"\n",
    "        \"STEP-BY-STEP PROCESS: \"\n",
    "        \"1. Load all three JSON files \"\n",
    "        \"2. Load insights from previous task \"\n",
    "        \"3. Create empty campus_checks list \"\n",
    "        \"4. FOR EACH of the 20 insights: \"\n",
    "        \"   a. Extract campus_id from insight \"\n",
    "        \"   b. Get actual data from JSONs for this campus_id \"\n",
    "        \"   c. Check for these error types: \"\n",
    "        \"      - NUMERIC SCORES SHOWN: If text contains '(XX puntos)' after categor√≠a ‚Üí ERROR \"\n",
    "        \"      - WRONG PERCENTAGE: Recalculate, if off by >3% ‚Üí ERROR \"\n",
    "        \"      - WRONG CATEGOR√çA: Compare to actual totales.X_categoria ‚Üí ERROR \"\n",
    "        \"      - INVENTED PUBLICATION: Check if theme exists in top_8_posts ‚Üí ERROR \"\n",
    "        \"   d. For EACH error: \"\n",
    "        \"      - Create FactCheckIssue object \"\n",
    "        \"      - Fill ALL fields (campus_id, campus_name, issue_type, incorrect_statement, correct_information, severity) \"\n",
    "        \"      - Add to issues_found array \"\n",
    "        \"   e. Count verified_claims and total_claims \"\n",
    "        \"   f. Set is_accurate = true if no errors, false if errors exist \"\n",
    "        \"   g. Add CampusFactCheck to campus_checks list \"\n",
    "        \"5. Calculate overall statistics \"\n",
    "        \"6. Return FactCheckReport \"\n",
    "        \"\\n\\n\"\n",
    "        \"CRITICAL: If you find errors, POPULATE issues_found array. Do not return empty array when errors exist. \"\n",
    "        \"CRITICAL: Check all 20 campus insights before returning.\"\n",
    "    ),\n",
    "\n",
    "    expected_output=\"FactCheckReport with campus_checks for all 20 campuses, with issues_found populated when errors exist\",\n",
    "\n",
    "    output_pydantic=FactCheckReport,\n",
    "    agent=agent_quality,\n",
    "    context=[task_insight],\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# DATA LOADING - STRUCTURED JSON FILES (Already Processed by Python Scripts)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"üìÇ Loading structured JSON files...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load Publications (Standard JSON format - NOT JSON Lines)\n",
    "print(\"üìÇ Loading structured JSON files...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load Publications (JSON LINES format - one object per line)\n",
    "publicaciones_data = []\n",
    "with open('Publicaciones_estructuradas_Top8.json', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            publicaciones_data.append(json.loads(line))\n",
    "\n",
    "print(f\"‚úÖ Publications loaded: {len(publicaciones_data)} campuses\")\n",
    "\n",
    "# Load Metrics (Standard JSON format)\n",
    "with open('metrics_estructurado.json', 'r', encoding='utf-8') as f:\n",
    "    metrics_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Metrics loaded: {len(metrics_data['regions'])} regions\")\n",
    "\n",
    "# Load Scores (Standard JSON format)\n",
    "with open('sdm_estructurado.json', 'r', encoding='utf-8') as f:\n",
    "    scores_data = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Scores loaded: {len(scores_data['campuses'])} campuses\")\n",
    "\n",
    "print(\"\\nüéØ All structured JSON files ready for validation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CREW CREATION - NEW 3-AGENT ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        agent_validator,\n",
    "        agent_insight,\n",
    "        agent_quality\n",
    "    ],\n",
    "    tasks=[\n",
    "        task_validator,\n",
    "        task_insight,\n",
    "        task_quality\n",
    "    ],\n",
    "    process=Process.sequential,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Crew configured with 3 agents and 3 tasks\")\n",
    "print(\"   Agent 1: Data Validator\")\n",
    "print(\"   Agent 2: Insight Generator\")\n",
    "print(\"   Agent 3: Quality Assurance\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CREW EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "try:\n",
    "    print(\"\\nüöÄ Starting crew execution...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Kick off the crew with file paths (agents will load the files)\n",
    "    result = crew.kickoff(inputs={\n",
    "        'publications_file': 'Publicaciones_estructuradas_Top8.json',\n",
    "        'metrics_file': 'metrics_estructurado.json',\n",
    "        'scores_file': 'sdm_estructurado.json',\n",
    "        'month': 'agosto',\n",
    "        'year': 2025\n",
    "    })\n",
    "\n",
    "    # Display intermediate results\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üìä INTERMEDIATE RESULTS:\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for i, task in enumerate(crew.tasks, 1):\n",
    "        agent_name = task.agent.role\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"üîπ Task {i}: {agent_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        if hasattr(task, 'output') and task.output:\n",
    "            output_preview = str(task.output.raw)[:800]\n",
    "            print(f\"{output_preview}...\")\n",
    "            \n",
    "            # Parse and show key metrics\n",
    "            try:\n",
    "                if i == 1:  # Validator\n",
    "                    print(f\"\\nüìã Validation Summary:\")\n",
    "                    print(f\"   Total Campuses: {task.output.pydantic.total_campuses}\")\n",
    "                    print(f\"   Complete: {task.output.pydantic.complete_campuses}\")\n",
    "                    print(f\"   Incomplete: {task.output.pydantic.incomplete_campuses}\")\n",
    "                \n",
    "                elif i == 2:  # Insight Generator\n",
    "                    print(f\"\\nüìù Insights Summary:\")\n",
    "                    print(f\"   Total Insights Generated: {task.output.pydantic.total_insights}\")\n",
    "                    print(f\"   Expected: 20 campuses\")\n",
    "                \n",
    "                elif i == 3:  # Quality Checker\n",
    "                    print(f\"\\n‚úîÔ∏è  Quality Check Summary:\")\n",
    "                    print(f\"   Campuses Checked: {task.output.pydantic.total_campuses_checked}\")\n",
    "                    print(f\"   Accurate: {task.output.pydantic.accurate_campuses}\")\n",
    "                    print(f\"   With Errors: {task.output.pydantic.campuses_with_errors}\")\n",
    "                    print(f\"   Total Issues: {task.output.pydantic.total_issues_found}\")\n",
    "                    print(f\"   Accuracy Rate: {task.output.pydantic.overall_accuracy_rate:.1f}%\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   (Could not parse structured output: {e})\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  No output available\")\n",
    "    \n",
    "    # Display final result\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚úÖ CREW EXECUTION COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nüìä FINAL OUTPUT:\")\n",
    "    print(\"=\" * 80)\n",
    "    print(result)\n",
    "    \n",
    "    # Save outputs to files\n",
    "    print(\"\\nüíæ Saving outputs to files...\")\n",
    "    \n",
    "    try:\n",
    "        # Save Validation Report\n",
    "        if hasattr(crew.tasks[0], 'output') and crew.tasks[0].output:\n",
    "            with open('validation_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(crew.tasks[0].output.pydantic.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "            print(\"   ‚úÖ Validation report saved: validation_report.json\")\n",
    "        \n",
    "        # Save Insights Report\n",
    "        if hasattr(crew.tasks[1], 'output') and crew.tasks[1].output:\n",
    "            with open('insights_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(crew.tasks[1].output.pydantic.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "            print(\"   ‚úÖ Insights report saved: insights_report.json\")\n",
    "        \n",
    "        # Save Quality Report\n",
    "        if hasattr(crew.tasks[2], 'output') and crew.tasks[2].output:\n",
    "            with open('quality_report.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(crew.tasks[2].output.pydantic.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "            print(\"   ‚úÖ Quality report saved: quality_report.json\")\n",
    "    \n",
    "    except Exception as save_error:\n",
    "        print(f\"   ‚ö†Ô∏è  Error saving files: {save_error}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéâ ALL TASKS COMPLETED!\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"‚ùå ERROR DURING EXECUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nError message: {str(e)}\")\n",
    "    print(\"\\nFull traceback:\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d87ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
